import streamlit as st
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from openai import OpenAI

# é…ç½®å¸¸é‡ - å¯æ ¹æ®å®é™…ç§¯åˆ†ç­–ç•¥è°ƒæ•´
DALLE_MODELS = {
    "dall-e-3": {"size_options": ["1024x1024", "1024x1792", "1792x1024"], "cost_factor": 4},
    "dall-e-2": {"size_options": ["256x256", "512x512", "1024x1024"], "cost_factor": 1}
}


def get_ai_response(user_prompt):
    model = ChatOpenAI(
        model='gpt-4o-mini',
        api_key=st.session_state['API_KEY'],
        base_url='https://twapi.openai-hk.com/v1'
    )
    chain = ConversationChain(llm=model, memory=st.session_state['memory'])
    return chain.invoke({'input': user_prompt})['response']


# ä¼˜åŒ–åçš„å›¾ç‰‡ç”Ÿæˆå‡½æ•° - é™ä½æˆæœ¬æ ¸å¿ƒé€»è¾‘
def generate_image(prompt):
    # æ£€æŸ¥ç¼“å­˜
    if 'image_cache' in st.session_state and prompt in st.session_state['image_cache']:
        st.write("â„¹ï¸ ä½¿ç”¨ç¼“å­˜å›¾ç‰‡ä»¥èŠ‚çœç§¯åˆ†")
        return st.session_state['image_cache'][prompt]

    client = OpenAI(
        api_key=st.session_state['API_KEY'],
        base_url='https://twapi.openai-hk.com/v1'
    )

    # æ ¹æ®æç¤ºå¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©æ¨¡å‹å’Œå°ºå¯¸
    model_choice, size_choice = select_optimal_config(prompt)

    try:
        response = client.images.generate(
            model=model_choice,
            prompt=prompt,
            size=size_choice,
            quality="standard",  # é¿å…ä½¿ç”¨é«˜æˆæœ¬çš„hdè´¨é‡
            n=1,  # åªç”Ÿæˆä¸€å¼ å›¾ç‰‡
        )
        url = response.data[0].url

        # ä¿å­˜åˆ°ç¼“å­˜
        if 'image_cache' not in st.session_state:
            st.session_state['image_cache'] = {}
        st.session_state['image_cache'][prompt] = url

        cost_info = f"ğŸ’¡ æˆæœ¬ä¼˜åŒ–ï¼šä½¿ç”¨{model_choice}@{size_choice}"
        st.write(cost_info)

        return url

    except Exception as e:
        # å‡ºé”™æ—¶å°è¯•é™çº§é…ç½®
        if model_choice == "dall-e-3":
            st.write(f"âš ï¸ DALL-E 3 å¤±è´¥ï¼Œå°è¯•é™çº§åˆ° DALL-E 2: {str(e)}")
            return generate_image_with_fallback(prompt, client)
        else:
            raise e


# æ ¹æ®æç¤ºå¤æ‚åº¦é€‰æ‹©æœ€ä¼˜é…ç½®
def select_optimal_config(prompt):
    # ç®€å•å¯å‘å¼ï¼šåŸºäºè¯æ•°å’Œç‰¹æ®Šå…³é”®è¯
    words = prompt.lower().split()
    complexity_score = len(words) + ('detailed' in words) * 5 + ('high quality' in words) * 10

    if complexity_score > 20:
        # å¤æ‚æç¤ºä½¿ç”¨DALL-E 3ï¼Œä½†é™ä½åˆ†è¾¨ç‡
        return "dall-e-3", "1024x1024"
    else:
        # ç®€å•æç¤ºä½¿ç”¨DALL-E 2 + å°å°ºå¯¸
        return "dall-e-2", "256x256"


# é™çº§ç­–ç•¥
def generate_image_with_fallback(prompt, client):
    try:
        response = client.images.generate(
            model="dall-e-2",
            prompt=prompt,
            size="512x512",  # ä¸­ç­‰å°ºå¯¸ä½œä¸ºé™çº§é€‰æ‹©
            quality="standard",
            n=1,
        )
        return response.data[0].url
    except Exception as e:
        # å†æ¬¡é™çº§åˆ°æœ€å°å°ºå¯¸
        response = client.images.generate(
            model="dall-e-2",
            prompt=prompt,
            size="256x256",
            quality="standard",
            n=1,
        )
        return response.data[0].url


# å…¶ä»–ä»£ç ä¿æŒä¸å˜...

# ä¸»åº”ç”¨é€»è¾‘
st.title('æˆ‘çš„ChatGPT')

with st.sidebar:
    api_key = st.text_input('è¯·è¾“å…¥ä½ çš„Keyï¼š', type='password')
    st.session_state['API_KEY'] = api_key

    # æ·»åŠ æˆæœ¬æ§åˆ¶é€‰é¡¹
    st.subheader("æˆæœ¬æ§åˆ¶")
    use_cache = st.checkbox("å¯ç”¨å›¾ç‰‡ç¼“å­˜", value=True)
    prefer_low_cost = st.checkbox("ä¼˜å…ˆä½¿ç”¨ä½æˆæœ¬æ¨¡å‹", value=True)

if 'messages' not in st.session_state:
    st.session_state['messages'] = [{'role': 'ai', 'content': 'ä½ å¥½ä¸»äººï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæˆ‘å«å°ç¾'}]
    st.session_state['memory'] = ConversationBufferMemory(return_message=True)

for message in st.session_state['messages']:
    role, content = message['role'], message['content']
    if role == 'ai' and content.startswith('![Image]('):
        st.chat_message(role).markdown(content)
    else:
        st.chat_message(role).write(content)

user_input = st.chat_input()
if user_input:
    if not api_key:
        st.info('è¯·è¾“å…¥è‡ªå·±ä¸“å±çš„Keyï¼ï¼ï¼')
        st.stop()
    st.chat_message('human').write(user_input)
    st.session_state['messages'].append({'role': 'human', 'content': user_input})

    with st.spinner('AIæ­£åœ¨æ€è€ƒï¼Œè¯·ç­‰å¾…â€¦â€¦'):
        if user_input.lower().startswith('/image'):
            image_prompt = user_input[len('/image'):].strip()
            if not image_prompt:
                resp_from_ai = "è¯·æä¾›å›¾ç‰‡æè¿°ï¼Œä¾‹å¦‚ï¼š/image ä¸€åªå¾®ç¬‘çš„çŒ«å’ª"
            else:
                try:
                    image_url = generate_image(image_prompt)
                    resp_from_ai = f"![Image]({image_url})"
                except Exception as e:
                    resp_from_ai = f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"
        else:
            resp_from_ai = get_ai_response(user_input)

        st.session_state['history'] = resp_from_ai
        st.chat_message('ai').markdown(resp_from_ai)
        st.session_state['messages'].append({'role': 'ai', 'content': resp_from_ai})